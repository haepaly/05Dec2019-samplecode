{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMCZJ/l3bjhbU+VDVp3e9Ax",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haepaly/05Dec2019-samplecode/blob/master/%5B%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5%5D_Knowledge_Distillation_%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] 기본 torch 관련 함수 import"
      ],
      "metadata": {
        "id": "_p6tTNsBRpP3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv2YAYQpRaQQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2] GPU 사용 확인"
      ],
      "metadata": {
        "id": "lFis69FnSAzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available() # gpu 사용 확인\n",
        "\n",
        "use_cuda=torch.cuda.is_available()\n",
        "device=torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device #cuda"
      ],
      "metadata": {
        "id": "jn4IsIDgSHg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3] Data 처리 관련"
      ],
      "metadata": {
        "id": "iyCoPMxgSP2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding = 4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.507, 0.487, 0.441),(0.267, 0.256, 0.276))\n",
        "])\n",
        "\n",
        "# Cifar-10 data download\n",
        "train_dataset = datasets.CIFAR10(root= '/data', train = True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root= '/data', train = False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "PblJuCQySTUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[4] 하이퍼 파라미터 설정 및 Loader 설정 \\\\\n",
        " * 지나친 고가 GPU 사용 경쟁을 막기 위해서 하기 파라미터는 수정 하지 말 것"
      ],
      "metadata": {
        "id": "xrerfAFZSpSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameter for network\n",
        "# Don't change it for this assignment\n",
        "epochs = 60\n",
        "batchsize = 128\n",
        "learning_rate = 0.01 #편의를 위해서 고정함\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0001\n",
        "\n",
        "# loader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchsize, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batchsize, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "xPQyHVgvSt1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[5] Teacher Model 생성 및 학습 수행\n",
        "* VGG style 10 layer network"
      ],
      "metadata": {
        "id": "pBtywNIKUG8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Teacher(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Teacher, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3,32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32,32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride =2),\n",
        "\n",
        "            nn.Conv2d(32,64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64,64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride =2),\n",
        "\n",
        "            nn.Conv2d(64,128,kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128,128,kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride =2),\n",
        "\n",
        "            nn.Conv2d(128,256,kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256,256,kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256,256,kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256,256,kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride =2),\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(1024,128),\n",
        "            nn.Linear(128,10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "teacher = Teacher().to(device) #Teacher모델 gpu에 생성\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(teacher.parameters(),lr=learning_rate,momentum=momentum,weight_decay=weight_decay)\n",
        "\n",
        "print(\"============Training start=============\")\n",
        "for epoch in range(epochs):\n",
        "    teacher.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        output = teacher(images)\n",
        "        loss = criterion(output,labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels.data).cpu().sum()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print('Epoch: {:3d} | Batch_idx: {:3d} |  Loss: {:.4f} | Acc: {:3.2f}%'.format(\n",
        "            epoch, idx, train_loss / (idx + 1), 100. * correct / total))\n",
        "print(\"============Training finished=============\")\n",
        "\n",
        "\n",
        "teacher.eval()  # 모델 평가모드\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    val_acc = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = teacher(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    print('Accuracy on the test set: {}'.format(val_acc))\n",
        "\n",
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': teacher.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': loss.item(),},\n",
        "    '/content/teacher_model.pth') # 모델 epochs, weight, opimizer 상태,loss 값 등 체크포인트 저장"
      ],
      "metadata": {
        "id": "WrC9-yE5UYhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[6] Student Model 생성 및 학습\n",
        "* VGG style 2 layer network\n"
      ],
      "metadata": {
        "id": "QvwtO4KkeLUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Student(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Student,self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3,16,kernel_size=3, padding =1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(16,16,kernel_size=3, padding =1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.fc_layers = nn.Linear(1024,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x= self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "student = Student().to(device)  #Student모델 gpu에 생성\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(student.parameters(),lr=learning_rate,momentum=momentum,weight_decay=weight_decay)\n",
        "\n",
        "print(\"============Training start=============\")\n",
        "for epoch in range(epochs):\n",
        "    student.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = student(images)\n",
        "        loss = criterion(output,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels.data).cpu().sum()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print('Epoch: {:3d} | Batch_idx: {:3d} |  Loss: {:.4f} | Acc: {:3.2f}%'.format(\n",
        "            epoch, idx, train_loss / (idx + 1), 100. * correct / total))\n",
        "\n",
        "print(\"============Training finished=============\")\n",
        "\n",
        "student.eval()  # 모델 평가모드\n",
        "with torch.no_grad(): #no gradient\n",
        "    correct = 0\n",
        "    val_acc = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = student(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    print('Accuracy on the test set: {}'.format(val_acc))\n",
        "\n",
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': student.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': loss.item(),\n",
        "    }, '/content/student_model.pth') # 모델 epochs, weight, opimizer 상태,loss 값 등 체크포인트 저장"
      ],
      "metadata": {
        "id": "P6yaNpWKeeJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[7] Knowledge Distillation"
      ],
      "metadata": {
        "id": "_AFGKyKK9-Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_teacher = Teacher().to(device)\n",
        "model_ckp = torch.load('/content/teacher_model.pth')\n",
        "trained_teacher.load_state_dict(model_ckp['model_state_dict']) #teacher model 새로 생성후 teacher_checkpoint load를 가져와서 trained_teacher에 적용\n",
        "\n",
        "\n",
        "lambda_ = 0.0001 #Knowledge distillation을 위한 parameters (lamda_, T)\n",
        "T = 4.5\n",
        "kl_div_loss = nn.KLDivLoss() #Knowledge distillation을 위한 Cost function\n",
        "\n",
        "print(\"============Training start=============\")\n",
        "for epoch in range(epochs):\n",
        "    student.train() #위에 train된 student 모델이 아니라 위에 만든 student를 그대로 다시 적용\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        s_output = student(images)\n",
        "        t_output =trained_teacher(images)\n",
        "\n",
        "        loss_SL = criterion(s_output, labels) # Standard Learning loss\n",
        "        loss_KD = kl_div_loss(F.log_softmax(s_output / T, dim=1),\n",
        "                            F.softmax(t_output / T, dim=1))\n",
        "        loss = (1 - lambda_) * loss_SL + lambda_ * T * T * loss_KD  # total_loss = (1 −λ)⋅loss_SL +λ⋅T^2 ⋅loss_KD)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(s_output.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels.data).cpu().sum()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print('Epoch: {:3d} | Batch_idx: {:3d} |  Loss: {:.4f} | Acc: {:3.2f}%'.format(\n",
        "            epoch, idx, train_loss / (idx + 1), 100. * correct / total))\n",
        "\n",
        "print(\"============Training finished=============\")\n",
        "\n",
        "\n",
        "student.eval()  # 모델 평가모드\n",
        "with torch.no_grad(): #no gradient\n",
        "    correct = 0\n",
        "    val_acc = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = student(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "print('Accuracy on the test set: {}'.format(val_acc))\n",
        "\n",
        "\n",
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': student.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': loss.item(),},\n",
        "    '/content/KD_model.pth') # KD 적용한 student 모델의 epochs, weight, opimizer 상태,loss 값 등 체크포인트 저장"
      ],
      "metadata": {
        "id": "ZkFTzfma-BDA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}